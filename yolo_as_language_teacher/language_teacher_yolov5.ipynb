{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yolo_as_language_teacher.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOehSZRgiPpKjURUl+IksKs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changsin/Medium/blob/main/yolo_as_language_teacher/language_teacher_yolov5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3IR2E-4bPaO"
      },
      "source": [
        "# Object Detection & Language Learning\n",
        "Learning language is a great challenge. It takes a long time to acquire a foreign language. Though there are many free language tutorials and Apps that make it easier, language learning is still hard. With the advancement of Deep Learning, why can't we use it help us learning a new language?\n",
        "\n",
        "One of the traditional \n",
        "Let's start with an object detection AI which can be used instead of flash cards."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmr3ahqma9uk"
      },
      "source": [
        "# Setup\n",
        "Install requirements and prepare the dataset for training.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip help install"
      ],
      "metadata": {
        "id": "ThUos559o_1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fNDvNWOWvpl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e77d9d6d-208e-44b7-bb85-3c8c27114ba1"
      },
      "source": [
        "!pip install youtube-dl==2020.12.2\n",
        "!pip install pafy\n",
        "\n",
        "!pip install Pillow==9.0.0\n",
        "!pip install yolov5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube-dl==2020.12.2 in /usr/local/lib/python3.7/dist-packages (2020.12.2)\n",
            "Requirement already satisfied: pafy in /usr/local/lib/python3.7/dist-packages (0.5.5)\n",
            "Requirement already satisfied: Pillow==9.0.0 in /usr/local/lib/python3.7/dist-packages (9.0.0)\n",
            "Obtaining file:///content/yolov5\n",
            "\u001b[31mERROR: File \"setup.py\" not found for legacy project file:///content/yolov5.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O1sEH6MGFlR"
      },
      "source": [
        "git clone Medium and yolov5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzHMg6kNuJay",
        "outputId": "14cf842f-fba7-4746-91e7-94368462e446"
      },
      "source": [
        "!git clone https://github.com/changsin/Medium/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Medium'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 71 (delta 27), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (71/71), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/changsin/DLTrafficCounter/"
      ],
      "metadata": {
        "id": "Z2YIoCzRm_TR",
        "outputId": "9665aec6-4399-4c56-bdc7-f433d1730975",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DLTrafficCounter'...\n",
            "remote: Enumerating objects: 277, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 277 (delta 17), reused 66 (delta 15), pack-reused 209\u001b[K\n",
            "Receiving objects: 100% (277/277), 226.60 MiB | 17.25 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n",
            "Checking out files: 100% (205/205), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Sp8S964yARl",
        "outputId": "e389116a-b418-44cd-f8cb-50bbc97c5af3"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install dependencies\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "clear_output()\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.11.0+cu113 (Tesla T4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccpQvXLlatKP"
      },
      "source": [
        "Download pretrained yolov5 model\n",
        "Choose one of the pretrained models from https://github.com/ultralytics/yolov5#inference\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5pTcJ1fyG5T",
        "outputId": "5852f0ff-6775-42df-8258-425381e21f40"
      },
      "source": [
        "!wget https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-23 05:01:12--  https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/56dd3480-9af3-11eb-9c92-3ecd167961dc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220523%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220523T050112Z&X-Amz-Expires=300&X-Amz-Signature=7f73880e6b1ff70d8f645090da21f0efff071fc3681b8fac1e3ebac16d322806&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-05-23 05:01:13--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/264818686/56dd3480-9af3-11eb-9c92-3ecd167961dc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220523%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220523T050112Z&X-Amz-Expires=300&X-Amz-Signature=7f73880e6b1ff70d8f645090da21f0efff071fc3681b8fac1e3ebac16d322806&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=264818686&response-content-disposition=attachment%3B%20filename%3Dyolov5s.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14795158 (14M) [application/octet-stream]\n",
            "Saving to: ‚Äòyolov5s.pt‚Äô\n",
            "\n",
            "yolov5s.pt          100%[===================>]  14.11M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-05-23 05:01:13 (228 MB/s) - ‚Äòyolov5s.pt‚Äô saved [14795158/14795158]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD1pTl7FuAVc"
      },
      "source": [
        "# YOLOv5 Detection Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlIHqa6lJEgy"
      },
      "source": [
        "# Detect and compare"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOm6wEw-rxG-",
        "outputId": "adee47d3-d7eb-4c0a-96a5-c4f2654f45af"
      },
      "source": [
        "%cd yolov5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g--Y7rPweNrM"
      },
      "source": [
        "## Pretrained model (baseline)\n",
        "- YOLOV5 Default Model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.5 --source ../DLTrafficCounter/data/bbox_highway/test --data ../Medium/yolo_as_language_teacher/coco128-vi.yaml"
      ],
      "metadata": {
        "id": "A-r6imfTRUiy",
        "outputId": "d8c1141d-68bb-4e96-88ac-7c9cc3f202c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=../DLTrafficCounter/data/bbox_highway/test, data=../Medium/yolo_as_language_teacher/coco128-vi.yaml, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 üöÄ v6.1-211-gcee5959 Python-3.7.13 torch-1.11.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 224 layers, 7266973 parameters, 0 gradients\n",
            "###['ng∆∞·ªùi', 'Xe ƒë·∫°p', 'xe √¥ t√¥', 'xe m√°y', 'M√°y bay', 'xe bu√Ωt', 't√†u h·ªèa', 'xe t·∫£i', 'thuy·ªÅn', 'ƒë√®n giao th√¥ng', 'v√≤i ch·ªØa ch√°y', 'bi·ªÉn b√°o d·ª´ng', 'ƒê·ªìng h·ªì ƒë·ªó xe', 'BƒÉng gh·∫ø', 'chim', 'con m√®o', 'ch√∫ ch√≥', 'con ng·ª±a', 'con c·ª´u', 'b√≤', 'con voi', 'con g·∫•u', 'ng·ª±a r·∫±n', 'h∆∞∆°u cao c·ªï', 'balo', '√¥', 't√∫i x√°ch tay', 'c√† v·∫°t', 'chi·∫øc vali', 'chi·∫øc dƒ©a nh·ª±a n√©m', 'v√°n tr∆∞·ª£t', 'tr∆∞·ª£t tuy·∫øt', 'b√≥ng th·ªÉ thao', 'c√°nh di·ªÅu', 'g·∫≠y b√≥ng ch√†y', 'gƒÉng tay b√≥ng ch√†y', 'v√°n tr∆∞·ª£t', 'v√°n l∆∞·ªõt s√≥ng', 'v·ª£t tennis', 'chai', 'ly r∆∞·ª£u', 't√°ch', 'c√°i nƒ©a', 'dao', 'c√°i th√¨a', 'b√°t', 'tr√°i chu·ªëi', 't√°o', 'b√°nh m√¨ sandwich', 'tr√°i cam', 'b√¥ng c·∫£i xanh', 'C√† r·ªët', 'b√°nh m√¨ k·∫πp x√∫c x√≠ch', 'pizza', 'b√°nh v√≤ng', 'b√°nh', 'c√°i gh·∫ø', 'ƒëi vƒÉng', 'c√¢y ch·∫≠u', 'Gi∆∞·ªùng', 'b√†n ƒÉn', 'ph√≤ng v·ªá sinh', 'TV', 'm√°y t√≠nh x√°ch tay', 'con chu·ªôt', 'Xa x√¥i', 'b√†n ph√≠m', 'ƒëi√™Ã£n thoaÃ£i di ƒë√¥Ã£ng', 'l√≤ vi s√≥ng', 'l√≤', 'M√°y n∆∞·ªõng b√°nh m√¨', 'b·ªìn r·ª≠a ch√©n', 't·ªß l·∫°nh', 's√°ch', 'ƒë·ªìng h·ªì', 'l·ªç c·∫Øm hoa', 'c√¢y k√©o', 'g·∫•u b√¥ng', 'm√°y s·∫•y t√≥c', 'B√†n ch·∫£i ƒë√°nh rƒÉng']\n",
            "Downloading https://ultralytics.com/assets/Arial.Unicode.ttf to /root/.config/Ultralytics/Arial.Unicode.ttf...\n",
            "image 1/5 /content/DLTrafficCounter/data/bbox_highway/test/Suwon_CH02_20200722_1600_WED_9m_RH_highway_TW5_rainy_FHD_096.png: 384x640 5 xe √¥ t√¥s, 1 xe bu√Ωt, Done. (0.017s)\n",
            "image 2/5 /content/DLTrafficCounter/data/bbox_highway/test/Suwon_CH02_20200722_1600_WED_9m_RH_highway_TW5_rainy_FHD_097.png: 384x640 5 xe √¥ t√¥s, 1 xe bu√Ωt, 1 t√†u h·ªèa, 1 xe t·∫£i, Done. (0.012s)\n",
            "image 3/5 /content/DLTrafficCounter/data/bbox_highway/test/Suwon_CH02_20200722_1600_WED_9m_RH_highway_TW5_rainy_FHD_098.png: 384x640 10 xe √¥ t√¥s, 4 xe t·∫£is, Done. (0.013s)\n",
            "image 4/5 /content/DLTrafficCounter/data/bbox_highway/test/Suwon_CH02_20200722_1600_WED_9m_RH_highway_TW5_rainy_FHD_099.png: 384x640 15 xe √¥ t√¥s, 1 xe bu√Ωt, 3 xe t·∫£is, Done. (0.012s)\n",
            "image 5/5 /content/DLTrafficCounter/data/bbox_highway/test/Suwon_CH02_20200722_1600_WED_9m_RH_highway_TW5_rainy_FHD_100.png: 384x640 13 xe √¥ t√¥s, 1 xe bu√Ωt, 2 xe t·∫£is, Done. (0.012s)\n",
            "Speed: 0.5ms pre-process, 13.1ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp5\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "!rm -rf /content/yolov5/runs/detect\n",
        "uploaded = files.upload()\n",
        "uploaded_filename = list(uploaded.items())[0][0]\n",
        "print(uploaded_filename)\n",
        "# im = Image.open(BytesIO(image_bytes))\n",
        "!python detect.py --weights yolov5s.pt --img 640 --conf 0.5 --source $uploaded_filename --data ../Medium/yolo_as_language_teacher/coco128-vi.yaml\n",
        "pred_image = cv2.imread('runs/detect/exp/' + uploaded_filename)\n",
        "cv2_imshow(pred_image)"
      ],
      "metadata": {
        "id": "fH1vhODTfDnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yolov5\n",
        "\n",
        "model_yolov5 = yolov5.load('yolov5s.pt')\n",
        "\n",
        "pred = model_yolov5(im)\n",
        "pred"
      ],
      "metadata": {
        "id": "MBTMyekpafyS",
        "outputId": "64d14595-f3e9-4cb0-a785-3adb2d9a191d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<yolov5.models.common.Detections at 0x7f02f1b66650>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePHBhTXUJbRZ"
      },
      "source": [
        "- Run against the customized and better vehicle detection model.\n",
        "(If you are running yourself, you need to modify the path of the weights file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MswmiNkiR_ON"
      },
      "source": [
        "# Detect and Count\n",
        "To detect and count each vehicle type, we need to parse the detection results returned by YOLO. Here is a brief explanation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL5gKdpA_VCg"
      },
      "source": [
        "## Explanation of detection results\n",
        "\n",
        "1. results.names contain the names of classes: e.g., 'person'. There are 80 of them by default corresponding to 80 COCO dataset classes.\n",
        "\n",
        "  ['person',\n",
        " 'bicycle',\n",
        " 'car',\n",
        " 'motorcycle',\n",
        " 'airplane',\n",
        " 'bus',\n",
        " 'train',\n",
        " 'truck',\n",
        " 'boat',\n",
        " 'traffic light',\n",
        " 'fire hydrant',\n",
        " 'stop sign',\n",
        " 'parking meter',\n",
        " 'bench',\n",
        " 'bird',\n",
        " 'cat',\n",
        " 'dog',\n",
        " 'horse',\n",
        " 'sheep',\n",
        " 'cow',\n",
        " 'elephant',\n",
        " 'bear',\n",
        " 'zebra',\n",
        " 'giraffe',\n",
        " 'backpack',\n",
        " 'umbrella',\n",
        " 'handbag',\n",
        " 'tie',\n",
        " 'suitcase',\n",
        " 'frisbee',\n",
        " 'skis',\n",
        " 'snowboard',\n",
        " 'sports ball',\n",
        " 'kite',\n",
        " 'baseball bat',\n",
        " 'baseball glove',\n",
        " 'skateboard',\n",
        " 'surfboard',\n",
        " 'tennis racket',\n",
        " 'bottle',\n",
        " 'wine glass',\n",
        " 'cup',\n",
        " 'fork',\n",
        " 'knife',\n",
        " 'spoon',\n",
        " 'bowl',\n",
        " 'banana',\n",
        " 'apple',\n",
        " 'sandwich',\n",
        " 'orange',\n",
        " 'broccoli',\n",
        " 'carrot',\n",
        " 'hot dog',\n",
        " 'pizza',\n",
        " 'donut',\n",
        " 'cake',\n",
        " 'chair',\n",
        " 'couch',\n",
        " 'potted plant',\n",
        " 'bed',\n",
        " 'dining table',\n",
        " 'toilet',\n",
        " 'tv',\n",
        " 'laptop',\n",
        " 'mouse',\n",
        " 'remote',\n",
        " 'keyboard',\n",
        " 'cell phone',\n",
        " 'microwave',\n",
        " 'oven',\n",
        " 'toaster',\n",
        " 'sink',\n",
        " 'refrigerator',\n",
        " 'book',\n",
        " 'clock',\n",
        " 'vase',\n",
        " 'scissors',\n",
        " 'teddy bear',\n",
        " 'hair drier',\n",
        " 'toothbrush']\n",
        " \n",
        "\n",
        "2. results.xyxyn: xy coordinates followed by the confidence and the class id. For instance, the first item is class_id=0 with 90% confidence which refers to 'person' class\n",
        "\n",
        "```\n",
        "[tensor([[ 0.73203,  0.43620,  0.85469,  0.88646,  0.90088,  0.00000],\n",
        "         [ 0.70586,  0.36276,  0.92344,  0.49609,  0.62939, 25.00000],\n",
        "         [ 0.58125,  0.40365,  0.73984,  0.78594,  0.46143, 77.00000],\n",
        "         [ 0.39355,  0.15990,  0.58789,  0.80365,  0.44385, 10.00000],\n",
        "         [ 0.19248,  0.50104,  0.20469,  0.54062,  0.29517,  0.00000]], device='cuda:0')]\n",
        "```\n",
        "results.xyxy and results.pred have the same content except in scientific notations.\n",
        "```\n",
        "[tensor([[1.75687e+03, 7.85156e+02, 2.05125e+03, 1.59562e+03, 9.00879e-01, 0.00000e+00],\n",
        "         [1.69406e+03, 6.52969e+02, 2.21625e+03, 8.92969e+02, 6.29395e-01, 2.50000e+01],\n",
        "         [1.39500e+03, 7.26562e+02, 1.77562e+03, 1.41469e+03, 4.61426e-01, 7.70000e+01],\n",
        "         [9.44531e+02, 2.87812e+02, 1.41094e+03, 1.44656e+03, 4.43848e-01, 1.00000e+01],\n",
        "         [4.61953e+02, 9.01875e+02, 4.91250e+02, 9.73125e+02, 2.95166e-01, 0.00000e+00]], device='cuda:0')]\n",
        "```\n",
        "3. results.imgs is the labeled image containing the detection results.\n",
        "4. results.save('folder') saves the detection result image to the folder.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t5lmfBT_6jl"
      },
      "source": [
        "With this information, we can now parse and count each vehicle type."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8xTskHP5jAy"
      },
      "source": [
        "## Plot annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJnZzGK2bh6F"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "def glob_files(path, file_type=\"*\"):\n",
        "    search_string = os.path.join(path, file_type)\n",
        "    files = glob.glob(search_string)\n",
        "\n",
        "    # print('searching ', path)\n",
        "    paths = []\n",
        "    for f in files:\n",
        "      if os.path.isdir(f):\n",
        "        sub_paths = glob_files(f + '/')\n",
        "        paths += sub_paths\n",
        "      else:\n",
        "        paths.append(f)\n",
        "\n",
        "    # We sort the images in alphabetical order to match them\n",
        "    #  to the annotation files\n",
        "    paths.sort()\n",
        "\n",
        "    return paths\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "path = \"/content/DLTrafficCounter/data/bbox_highway/test/\"\n",
        "\n",
        "image_filenames = glob_files(path, file_type=\"*.png\")\n",
        "image_filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcB-u8pIQvKD",
        "outputId": "5b0f30c0-e837-4128-d03a-e64d204febf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/DLTrafficCounter/data/bbox_highway/test/Suwon_CH02_20200722_1600_WED_9m_RH_highway_TW5_rainy_FHD_096.png',\n",
              " '/content/DLTrafficCounter/data/bbox_highway/test/Suwon_CH02_20200722_1600_WED_9m_RH_highway_TW5_rainy_FHD_097.png',\n",
              " '/content/DLTrafficCounter/data/bbox_highway/test/Suwon_CH02_20200722_1600_WED_9m_RH_highway_TW5_rainy_FHD_098.png',\n",
              " '/content/DLTrafficCounter/data/bbox_highway/test/Suwon_CH02_20200722_1600_WED_9m_RH_highway_TW5_rainy_FHD_099.png',\n",
              " '/content/DLTrafficCounter/data/bbox_highway/test/Suwon_CH02_20200722_1600_WED_9m_RH_highway_TW5_rainy_FHD_100.png']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pred.names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl0UzvnqRpep",
        "outputId": "94e60c91-14e0-416f-8842-0a7ab8483d1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Medium/yolo_as_language_teacher/coco128-vi.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1G4X4dCSYxc",
        "outputId": "65bbbedb-a575-49b7-e3be-8271484d49a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Medium/yolo_as_language_teacher/coco128-vi.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Vietnamese class names from the yaml file"
      ],
      "metadata": {
        "id": "FvQrBeVuaLrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "filename_coco128_vn = '/content/Medium/yolo_as_language_teacher/coco128-vi.yaml'\n",
        "coco_vn = yaml.safe_load(Path(filename_coco128_vn).read_text())"
      ],
      "metadata": {
        "id": "lfssrWaoSUlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred.names"
      ],
      "metadata": {
        "id": "q1OE23LDWpLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coco_vn['names']"
      ],
      "metadata": {
        "id": "HSEUZ4ISWA14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a dictionary out of English and Vietnamese class names"
      ],
      "metadata": {
        "id": "OxqouBZ3aWJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coco_classes_en_vi = dict(zip(pred.names, coco_vn['names']))"
      ],
      "metadata": {
        "id": "05k-eOZRZG4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in coco_classes_en_vi.items():\n",
        "  print(\"{}: {}\".format(k, v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbd7XVPFYmb5",
        "outputId": "63660612-ede0-46cc-d3cf-8365e322bec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "person: ng∆∞·ªùi\n",
            "bicycle: Xe ƒë·∫°p\n",
            "car: xe √¥ t√¥\n",
            "motorcycle: xe m√°y\n",
            "airplane: M√°y bay\n",
            "bus: xe bu√Ωt\n",
            "train: t√†u h·ªèa\n",
            "truck: xe t·∫£i\n",
            "boat: thuy·ªÅn\n",
            "traffic light: ƒë√®n giao th√¥ng\n",
            "fire hydrant: v√≤i ch·ªØa ch√°y\n",
            "stop sign: bi·ªÉn b√°o d·ª´ng\n",
            "parking meter: ƒê·ªìng h·ªì ƒë·ªó xe\n",
            "bench: BƒÉng gh·∫ø\n",
            "bird: chim\n",
            "cat: con m√®o\n",
            "dog: ch√∫ ch√≥\n",
            "horse: con ng·ª±a\n",
            "sheep: con c·ª´u\n",
            "cow: b√≤\n",
            "elephant: con voi\n",
            "bear: con g·∫•u\n",
            "zebra: ng·ª±a r·∫±n\n",
            "giraffe: h∆∞∆°u cao c·ªï\n",
            "backpack: balo\n",
            "umbrella: √¥\n",
            "handbag: t√∫i x√°ch tay\n",
            "tie: c√† v·∫°t\n",
            "suitcase: chi·∫øc vali\n",
            "frisbee: chi·∫øc dƒ©a nh·ª±a n√©m\n",
            "skis: v√°n tr∆∞·ª£t\n",
            "snowboard: tr∆∞·ª£t tuy·∫øt\n",
            "sports ball: b√≥ng th·ªÉ thao\n",
            "kite: c√°nh di·ªÅu\n",
            "baseball bat: g·∫≠y b√≥ng ch√†y\n",
            "baseball glove: gƒÉng tay b√≥ng ch√†y\n",
            "skateboard: v√°n tr∆∞·ª£t\n",
            "surfboard: v√°n l∆∞·ªõt s√≥ng\n",
            "tennis racket: v·ª£t tennis\n",
            "bottle: chai\n",
            "wine glass: ly r∆∞·ª£u\n",
            "cup: t√°ch\n",
            "fork: c√°i nƒ©a\n",
            "knife: dao\n",
            "spoon: c√°i th√¨a\n",
            "bowl: b√°t\n",
            "banana: tr√°i chu·ªëi\n",
            "apple: t√°o\n",
            "sandwich: b√°nh m√¨ sandwich\n",
            "orange: tr√°i cam\n",
            "broccoli: b√¥ng c·∫£i xanh\n",
            "carrot: C√† r·ªët\n",
            "hot dog: b√°nh m√¨ k·∫πp x√∫c x√≠ch\n",
            "pizza: pizza\n",
            "donut: b√°nh v√≤ng\n",
            "cake: b√°nh\n",
            "chair: c√°i gh·∫ø\n",
            "couch: ƒëi vƒÉng\n",
            "potted plant: c√¢y ch·∫≠u\n",
            "bed: Gi∆∞·ªùng\n",
            "dining table: b√†n ƒÉn\n",
            "toilet: ph√≤ng v·ªá sinh\n",
            "tv: TV\n",
            "laptop: m√°y t√≠nh x√°ch tay\n",
            "mouse: con chu·ªôt\n",
            "remote: Xa x√¥i\n",
            "keyboard: b√†n ph√≠m\n",
            "cell phone: ƒëi√™Ã£n thoaÃ£i di ƒë√¥Ã£ng\n",
            "microwave: l√≤ vi s√≥ng\n",
            "oven: l√≤\n",
            "toaster: M√°y n∆∞·ªõng b√°nh m√¨\n",
            "sink: b·ªìn r·ª≠a ch√©n\n",
            "refrigerator: t·ªß l·∫°nh\n",
            "book: s√°ch\n",
            "clock: ƒë·ªìng h·ªì\n",
            "vase: l·ªç c·∫Øm hoa\n",
            "scissors: c√¢y k√©o\n",
            "teddy bear: g·∫•u b√¥ng\n",
            "hair drier: m√°y s·∫•y t√≥c\n",
            "toothbrush: B√†n ch·∫£i ƒë√°nh rƒÉng\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW_fk9bYc7YM"
      },
      "source": [
        "# Real-time inferencing\n",
        "With the vehicle counting code, we can actually test against a real stream of traffic data. Here is an example. You will see that it does not work in all cases. More data is needed to make it robust, but now you know how to do it. Enjoy!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "filename_coco128_vi = '/content/Medium/yolo_as_language_teacher/coco128-vi.yaml'\n",
        "names_vi = None\n",
        "with open(filename_coco128_vi, errors='ignore') as f:\n",
        "    names_vi = yaml.safe_load(f)['names']  # class names\n",
        "    print(\"###{}\".format(names_vi))"
      ],
      "metadata": {
        "id": "y_lkWFY7l5E2",
        "outputId": "bc18418e-a7a5-49be-f085-0cb76a7ee6b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###['ng∆∞·ªùi', 'Xe ƒë·∫°p', 'xe √¥ t√¥', 'xe m√°y', 'M√°y bay', 'xe bu√Ωt', 't√†u h·ªèa', 'xe t·∫£i', 'thuy·ªÅn', 'ƒë√®n giao th√¥ng', 'v√≤i ch·ªØa ch√°y', 'bi·ªÉn b√°o d·ª´ng', 'ƒê·ªìng h·ªì ƒë·ªó xe', 'BƒÉng gh·∫ø', 'chim', 'con m√®o', 'ch√∫ ch√≥', 'con ng·ª±a', 'con c·ª´u', 'b√≤', 'con voi', 'con g·∫•u', 'ng·ª±a r·∫±n', 'h∆∞∆°u cao c·ªï', 'balo', '√¥', 't√∫i x√°ch tay', 'c√† v·∫°t', 'chi·∫øc vali', 'chi·∫øc dƒ©a nh·ª±a n√©m', 'v√°n tr∆∞·ª£t', 'tr∆∞·ª£t tuy·∫øt', 'b√≥ng th·ªÉ thao', 'c√°nh di·ªÅu', 'g·∫≠y b√≥ng ch√†y', 'gƒÉng tay b√≥ng ch√†y', 'v√°n tr∆∞·ª£t', 'v√°n l∆∞·ªõt s√≥ng', 'v·ª£t tennis', 'chai', 'ly r∆∞·ª£u', 't√°ch', 'c√°i nƒ©a', 'dao', 'c√°i th√¨a', 'b√°t', 'tr√°i chu·ªëi', 't√°o', 'b√°nh m√¨ sandwich', 'tr√°i cam', 'b√¥ng c·∫£i xanh', 'C√† r·ªët', 'b√°nh m√¨ k·∫πp x√∫c x√≠ch', 'pizza', 'b√°nh v√≤ng', 'b√°nh', 'c√°i gh·∫ø', 'ƒëi vƒÉng', 'c√¢y ch·∫≠u', 'Gi∆∞·ªùng', 'b√†n ƒÉn', 'ph√≤ng v·ªá sinh', 'TV', 'm√°y t√≠nh x√°ch tay', 'con chu·ªôt', 'Xa x√¥i', 'b√†n ph√≠m', 'ƒëi√™Ã£n thoaÃ£i di ƒë√¥Ã£ng', 'l√≤ vi s√≥ng', 'l√≤', 'M√°y n∆∞·ªõng b√°nh m√¨', 'b·ªìn r·ª≠a ch√©n', 't·ªß l·∫°nh', 's√°ch', 'ƒë·ªìng h·ªì', 'l·ªç c·∫Øm hoa', 'c√¢y k√©o', 'g·∫•u b√¥ng', 'm√°y s·∫•y t√≥c', 'B√†n ch·∫£i ƒë√°nh rƒÉng']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_yolov5 = yolov5.load('yolov5s.pt')"
      ],
      "metadata": {
        "id": "8xM1HVn8r7t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(model_yolov5)"
      ],
      "metadata": {
        "id": "BaoCWi9Yr-YO",
        "outputId": "28e54d91-153a-4661-98d4-5009bb212bed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "yolov5.models.common.AutoShape"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pafy\n",
        "import cv2\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Live Vietnam Walk Online Tour | Walking Beautiful Vietnam Hanoi Street Î≤†Ìä∏ÎÇ® ÌïòÎÖ∏Ïù¥ | „Éô„Éà„Éä„É†„É©„Ç§„Éñ Vi√™t Nam\n",
        "url = \"https://youtu.be/K13pAsEcJPQ\"\n",
        "\n",
        "video = pafy.new(url)\n",
        "best = video.getbest(preftype=\"mp4\")\n",
        "model_yolov5 = yolov5.load('yolov5s.pt')\n",
        "\n",
        "while True:\n",
        "    capture = cv2.VideoCapture(best.url)\n",
        "    grabbed, frame = capture.read()\n",
        "\n",
        "    temp = Path(f'temp.jpg')\n",
        "    # Save image with temporary name\n",
        "    cv2.imwrite(str(temp), frame)\n",
        "    print(temp)\n",
        "\n",
        "    clear_output(wait=True)\n",
        "\n",
        "    !rm -rf /content/yolov5/runs/detect\n",
        "    !python detect.py --weights yolov5s.pt --img 640 --conf 0.5 --source $temp --data ../Medium/yolo_as_language_teacher/coco128-vi.yaml\n",
        "    pred_image = cv2.imread(\"runs/detect/exp/{}\".format(str(temp)))\n",
        "\n",
        "    cv2_imshow(pred_image)\n",
        "\n",
        "    time.sleep(5)"
      ],
      "metadata": {
        "id": "KsIyZwDQjmTn",
        "outputId": "9646b4a2-4f50-4404-b7e1-3a07913d31cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=temp.jpg, data=../Medium/yolo_as_language_teacher/coco128-vi.yaml, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n",
            "YOLOv5 üöÄ v6.1-211-gcee5959 Python-3.7.13 torch-1.11.0+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eyg6oItO1ucB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}